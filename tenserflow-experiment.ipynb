{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all libraries used for Tneserflow\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras import optimizers\n",
    "import pathlib\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Conv2D, MaxPool2D, Activation, Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers, optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30612 validated image filenames belonging to 80 classes.\n",
      "Found 7653 validated image filenames belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# Import data from folders and load into the system\n",
    "train_path = os.getcwd() +'/data/train_set/train_set'\n",
    "test_path = os.getcwd() +'/data/test_set'\n",
    "train_csv_path = os.getcwd() + '/train_labels.csv'\n",
    "test_csv_path = os.getcwd() + '/sample.csv'\n",
    "\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "train_csv.head()\n",
    "\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "test_csv.head()\n",
    "\n",
    "img_height, img_width = 256, 256\n",
    "\n",
    "train_csv['label'] = train_csv['label'].astype(str)\n",
    "test_csv['label'] = test_csv['label'].astype(str)\n",
    "    \n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "#     validation_split=0.15,\n",
    "#     shear_range=0.2,\n",
    "#     zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_csv,\n",
    "    directory = train_path,\n",
    "    subset = None,\n",
    "    x_col = 'img_name',\n",
    "    y_col = 'label',\n",
    "    color_mode = 'grayscale',\n",
    "    target_size = (256, 256),\n",
    "    class_mode = 'categorical'\n",
    ")\n",
    "\n",
    "val_generator = train_datagen.flow_from_dataframe(\n",
    "    test_csv,\n",
    "    directory = test_path,\n",
    "    subset = None,\n",
    "    x_col = 'img_name',\n",
    "    y_col = 'label',\n",
    "    color_mode = 'grayscale',\n",
    "    target_size = (256, 256),\n",
    "    class_mode = 'categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 1)\n",
      "(32, 256, 256, 1)\n",
      "(32, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO Display 9 train images with their labels\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "# plt.imshow(train_generator[0][0])\n",
    "\n",
    "# for images in train_generator:\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow(images[i])\n",
    "#         plt.title(train_csv.label[i])\n",
    "#         plt.axis(\"off\")\n",
    "\n",
    "print(train_generator[0][0].shape)\n",
    "\n",
    "for image_batch, labels_batch in train_generator:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the data\n",
    "# normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
    "\n",
    "# normalized_ds = train_generator.map(lambda x: (normalization_layer(x)))\n",
    "\n",
    "# print(normalized_ds.take(1))\n",
    "\n",
    "# for i in normalized_ds.take(1):\n",
    "#     print('e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 1)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(80, activation='relu'),\n",
    "#   layers.Dense(num_classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_9 (Rescaling)      (None, 256, 256, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 256, 256, 16)      160       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 128, 128, 16)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 128, 128, 32)      4640      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 64, 64, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 65536)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 80)                5242960   \n",
      "=================================================================\n",
      "Total params: 5,266,256\n",
      "Trainable params: 5,266,256\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Compile the model\n",
    "# model.compile(optimizer='adam',\n",
    "#               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "#               metrics=['accuracy'])\n",
    "\n",
    "\n",
    "model.compile(optimizer=Adam(lr=0.0001),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.preprocessing.image.DataFrameIterator object at 0x7ff2fcfa69d0>\n"
     ]
    }
   ],
   "source": [
    "# Create an dataset\n",
    "\n",
    "print(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 624/2000 [========>.....................] - ETA: 34:15 - loss: 14.2568 - accuracy: 0.0173"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "# MOET DATASET MAKEN MET LABLES \n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch = 2000,\n",
    "    epochs = 10,\n",
    "    validation_data = val_generator,\n",
    "    validation_steps = 64\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
